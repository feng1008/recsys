本文主要讲述矩阵分解(主要包括SVD及其改进方法)在推荐系统中的应用.



#### 1. SVD与原理


##### 1)basic SVD
经典的SVD是将一个user与item的评分矩阵R, 分解为两个矩阵P和Q的乘积, 其中P, Q分别代表用户与商品的矩阵.


假设R是一个m*n 的矩阵, 则我们通过矩阵分解, 将其投影到一个相对较小(k维)的隐因子空间,得到隐向量空间的用户矩阵P(m\*k维),商品矩阵Q(k\*n维).并使得P\*Q还原后的矩阵`$\hat R$`近似等于评分矩阵R.

`$\hat r_{ui} = p_u^Tq_i$`

损失函数(假设使用平方误差)则为:

`$SSE = \sum_{ui}(r_{ui} - \hat r_{ui})^2$`


##### 2) 正则化SVD

考虑到过拟合的问题,可以在SVD的基础上加上正则化,此时SVD的目标函数不变,但损失函数变为:

`$SSE = \sum_{ui}(r_{ui} - \hat r_{ui})^2 +\frac{1}{2} \lambda \sum_{u}|p_u|^2 + \frac{1}{2} \lambda \sum_{i}|q_i|^2$`


##### 3) 加入偏置的SVD

由于用户对商品的评分不仅仅不仅仅取决于用户和商品之间的关系,还取决于用户和商品独有的性质(比如有些用户对商品的评分普遍偏低, 有些商品得到的评分普遍偏高等原因). 考虑对目标函数加入用户和商品的属性值`$b_u$` 和 `$b_i$`. 于是目标函数`$\hat r_{ui}$`则为:


`$\hat r_{ui} = \mu + b_u + b_i + p_u^Tq_i$`

其中, `$\mu$` 为总的平均分

损失函数的形式不变, 也可以加上正则化系数



##### 4) ASVD

考虑到用户商品的评分矩阵大多数为0的一个原因是用户并不知道该商品的存在, 因此将用户对这类商品的评分也当做负样本是不合理的.ASVD将用户矩阵P取代为用户评过分的商品和用户浏览过但未评分的商品来描述用户.其目标函数则改为:


`$\hat r_{ui} = \mu + b_u + b_i + q_i^T(|R(U)|^{-\frac{1}{2}}\sum_{j}(r_{ui} - \mu - b_u - b_i)x_j + |N(u)|)^{-\frac{1}{2}}\sum_jy_j) $`

其中, R(u)表示用户u评过分的商品集合, N(u)表示用户u浏览过但没有评分的的商品的集合,`$x_j$` 和 `$y_j$`是商品的属性.


##### 5) SVD++

考虑到隐式反馈(比如用户浏览记录, 因为用户的浏览代表了用户喜好, 而且现实中显式反馈的数据相对较少)的重要性, SVD++将隐式反馈考虑到推荐系统中.这样用户兴趣 = 显式兴趣 +隐式反馈

`$\hat r_{ui} = \mu + b_u + b_i + q_i(p_u + \frac{1}{\sqrt{|N_u|}}\sum_{j}y_j )$`

其中, N(u)表示用户u的行为商品集, `$y_j$`表示商品 j表达的隐式反馈.



#### ２．求解过程


和大多数机器学习算法一样, SVD目标也是极小化上述的损失函数SSE, 因此可以用梯度下降(一般理解为mini-batch梯度下降)及其改进方法来求解, 当然也可以用牛顿方法及其改进方法(但似乎这类方法只用在回归上求解比较多)来求解.梯度下降的改进方法还包括Moments, Adagrad, Adam, Rmsprop, NAdam等.


`$\frac{\partial}{\partial p_{uk}} SSE $`  


`$= \frac{\partial}{\partial p_{uk}} (r_{ui} - \hat r_{ui}) ^2$`

`$= -e _{ui} q_{ki}$`


因此, 得到`$p_{uk}$`, `$q_{ki}$` 的更新公式为:

`$p_{uk} := p_{uk} + \eta e_{ui} q_{ki}$`

`$q_{ki} := q_{ki} + \eta e_{ui} p_{uk}$`


同理, 对SVD的其他改进方法或者使用Adam等其他方法来优化损失函数的时候, 迭代公司也是同样的原理.

