#### 摘要

随着网络信息的爆炸性发展，推荐系统已经成为了一种有效、关键的解决方案来解决信息过载。近年来，深度学习在语音、图像、自然语言处理上的巨大进步已经吸引了巨大的关注。同时，近年来的研究也印证了将其应用到搜索、推荐上的有效性。将深度学习应用到推荐系统因其在state-of-art 上的表现和高质量的推荐已经吸引了大量的关注。相比传统推荐模型，深度学习对用户的需求、商品的属性及其历史上的相互作用有一个更好的理解。


##### 引言




#### 分类介绍及其分析

这一节我们介绍我们对基于深度学习的推荐系统的方法的分类的模式，并对列出的一些研究进行全面的分析。


#### 3.1 Two-dimension 分类模式

为了对现今的研究的一个概述，我们提出对当前两种不同视角的研究的一个划分方法：神经网络模型和集成模型。图1 简单总结了这两类方法的分类标准。

3.1.1 神经网络模型

我们把基于深度学习的推荐模型分为两类：使用单一深度学习技术的模型和使用混合深度学习技术的模型。

1) 使用单一深度学习技术的模型：在这一类中，模型被分为8个子类，对应8种不同的深度学习模型：MLP, AE, CNN, RNN, DSSM, RBM, NADE 和 GAN。其深度学习的技术决定了对应模型的优势和应用性。比如说MLP使用于建模用户和商品之间的非线性交叉性；CNN适合提取不同数据源（比如文本和视觉数据）局部和全局的表示；RNN适合建模动态变化的评分数据和受时序影响的信息；DSSM适合描述用户和商品之间的语义匹配。


2) 深度混合模型：有一些基于深度学习的推荐模型使用了多种深度学习技术。其动机是不同的深度学习技术可以互相弥补其不足使之成为一个强大的模型。有一些对这八种方法进行结合的实现但还没有完全开发出来。我们再section 5里列出了现存的这些技术的融合的模型，我们这里的深度混合模型和[21]中使用生成模型和判别模型的混合模型不是一回事。


集成模型：根据其结合了传统推荐模型和深度模型还是只使用了深度模型来区分。

结合传统推荐模型的深度模型：有些研究尝试将深度学习和传统推荐模型（比如MF, PMF, FM, KNN）相结合。根据其余传统模型的结合程度又被进一步分为强耦合和弱耦合模型。比如当使用自编码技术来学习输入到因子模型的特征表达而且自编码模型和因子模型的参数是同时优化的时候，我们称之为强耦合模型。这样，因子模型和特征学习的过程互相影响。当参数分开进行学习的时候，我们称之为弱耦合模型。

只使用深度学习的推荐模型：这种情况，推荐模型的训练和预测仅仅使用深度学习技术。

表2总结了一些基于以上分类的研究工作。需要指出的是，基于GAN的推荐还没有任何相关的研究工作。


#### 3.2定性分析

在这里，我们对研究成果的数量、实验数据集、评价标准和参考文献做一个分析。

图2(a)阐述了自2007年以后每年的研究成果数量。在最近的5年相关研究成果呈指数型增长。从表2我们发现，AE, RNN, CNN 和MLP的研究更为广泛。接下来的是深度混合模型、RBM和DSSM。近年来的推荐系统的研究尝试用GAN和NADE。

图2(c) 和2(d)显示了在我们参考的工作中使用的数据集和评价标准的情况。两个电影推荐的数据集：Movielens和Netflix是两个最常使用的数据集。其他还有Amazon、Yelp、CiteUlike的使用也很广泛。对于评价指标，RMSE和MSE使用最多，接着还有recall, precision, NDCG和AUC。recall, precision 和F1在分类任务中使用较为常见。

表3显示了年引用次数大于10的研究成果的影响因子。从中我们可以发现哪些深度模型的影响因子更大。有些模型可以会随着时间的流逝影响力逐渐下降。

还一个我们想要指出的是在不同推荐任务上研究成果的占比。Ranking prediction(66%)是研究最多的。其他还有prevailing paradigm 和rating prediction(28%)，只有很少数的工作(6%)将推荐问题转化为分类问题。

#### 3.3应用领域

在所有review的文献中，有些推荐模型指定了特定的领域。通用的推荐系统在某一特定领域可能表现并不理想。这些领域通常有自己独特的属性需要自己单独深入研究。我们将我们参考的研究工作的领域分为以下几种：图像推荐、品类推荐、POI推荐、新闻推荐、标签推荐、报价推荐、citation推荐。表4 是对其的一个总结：


### 4基于深度学习的推荐系统

这一节我们将着重介绍在我们提出的分类框架下的推荐系统研究的概览。我们旨在强调最著名、最有前景的研究工作而不是提供一个清单。

#### 4.1基于MLP的推荐系统

MLP是一个简单但又有效的模型，在很多领域尤其工业界广泛使用。MLP被证明可以在一定程度上逼近任何函数。它是很多当前先进的模型的基础。

##### 4.1.1只基于MLP的推荐

Neural Collaborative Filtering：在很多情况下，推荐被认为是用户偏好和商品特征的一个二阶交叉。比如说，MF将评分矩阵分解成一个低维的潜在用户空间和一个低维的潜在商品空间。基于内容的推荐系统根据用户或商品之间的相似性来生成最后的推荐结果。因此，建立一个用户和item之间的二阶交叉的双重网络就很自然了。Neural
Collaborative Filtering (NCF)就是一种旨在获取用户和item之间的非线性关系的框架。

假设`$s^{user}_u$` 和 `$s_i^{item}$` 分别表示用户信息和item信息（或者只是用户和item的一个one-hot表示），NCF的目标函数如下：

`$\hat{r_{ui}} = f(U^T * s^{user}_u, V^T * s_i^{item} | U, V, \theta)$`

其中，f表示MLP函数，`$\theta$` 是网络的参数，损失函数定义为加权的均方误差。

`$ L =  $`

其中， `$w_{ui}$`是训练实例(u, i)的权重，对于二值评分和隐式反馈，作者提出一种概率函数来将输出限定在(0, 1)之间，然后将损失函数修正为交叉熵形式。

`$ L = $`

由于有大量的未观测实例， NCF使用Negative Sampling来减少训练集，这极大提高了训练效率，传统的MF可以看成是NCF的一个特例。因此将MF与NCF融合成一个泛化能力更强的模型，其既有MF的线性特征又有MLP的非线性特征。


He[118]将NCF模型拓展到跨领域的推荐，比如讲信息领域的东西推荐给社交网络的潜在用户，并提出一个社交协同排序的推荐系统。另一个拓展是CCCFNet(Cross-domain Content-boosted Collaborative Filtering
neural Network)， 它的基本组成部分是一个用户和item的双向神经网路。它用内积为用户-item最后一层的交叉关系建模。为了对内容信息进行emedding，作者将双向神经网络的每个网络分为两部分：协同过滤向量（用户和item的隐向量）和内容信息（用户在各个item上的偏好和item的feature）。在此基础上建立一个多视图的神经网络来进行跨领域的推荐。

Wide&Deep Learning：这一模型既可以进行分类也可以回归，它最初是用在Google Play的App推荐。Wide部分是一个简单的单层模型，也可以看成是一个广义线性模型。Deep部分是一个多层感知机。通过将这两种模型结合起来可以使推荐系统既有Memorization（记忆）又有泛化能力。Memorization是Wide部分从历史数据中的特征直接获取而来的。同时Deep部分通过生成更多广义的抽象的表示来获得泛化能力。这一模型不仅仅提高了推荐系统的准确率也提高了其推荐结果的多样性。


Wide部分：`$y = W_{wide}^T\left\{x, \phi(x) \right\} + b$`，其中`$W_{wide}^T$` 和`$b$`是模型的参数，`$x` 和 `$\phi(x)$`分别是元特征和衍生出来的特征（比如特征之间的交叉）。deep部分的每个神经元都和多层感知机是一致的。因此，Wide & Deep模型的目标函数形式为：
`$P(\hat r_{ui} = 1 | x) = \sigma(W_{wide}^T\left\{x, \phi(x) \right\}, W_{deep}^T a^{l_f} + bias) $`。

其中`$\sigma()$`是sigmoid函数，`$\hat r_{ui}$`是二值的标签，`$a^{l_f}$`是最后一层的激活。最后，这一混合模型使用ftrl进行优化，最后的推荐结果是根据预测的结果。

Chen[9]将这一方法进行拓展，提出了一个局部链接的Wide & Deep方法来进行工业级的大规模推荐任务。它使用局部连接网络来取代Deep部分，把训练时间减少了一个数量级。


Wide & Deep网络的另一个重要部分是从wide和deep部分中挑选特征。换句话说，推荐系统应该能够判别哪些特征是memorized还是generalized的。还有，特征的内积也需要手工设计，预处理步骤会严重影响模型的使用。为减少手工提取特征的工作量，Guo[35]提出了DeepFM。

DeepFM[35]是一个整合了FM和MLP的端到端模型。使得模型可以通过深度网络来描述高阶特征，使用FM来描述低阶特征的交叉。FM使用加法和内积操作来获取特征间的相互关系，MLP利用非线性激活和深度结构来描述高阶的特征关系。将这两种方法进行结合是收到了wide & Deep 的启发。相比wide & Deep，DeepFM不需要人工的特征提取，它使用FM来取代宽度部分。图3描述了deepFM的结构。DeepFM的输入x是一个(u, i)的用户-item的对。FM和MLP的输出分别用`$y_{FM}(x)$` 和 `$y_{MLP}(x)$`来表示，最后的输出结果为：

`$\hat r_{ui} = \sigma(y_{FM}(x) + y_{MLP}(x))$`

其中 `$\sigma$`是sigmoid函数 。



##### 4.1.2结合传统推荐方法的MLP

Attentive协同过滤：Attention机制是受人类视觉注意力启发的。比如说，人类只需要聚焦物体的特定部分就可以认识和识别它。Attention机制能够过滤掉原输入的无关紧要的特征，减小噪音的影响。Attention机制的模型已经在语音识别[13]和机器翻译[72]上表现出非常promising 结果。近期的一些工作[10, 32, 91]已经表明将它与一些深度学习技术（比如MLP, CNN, RNN）能够很好的提升推荐模型的效果。chen[10]提出一个Attention协同过滤模型，他将一个两层的Attention机制引入到隐向量模型中，它是一个包含item层和连接层的Attention的MLP。item层的Attention用于寻找最具有代表性的item特征给用户，连接层的Attention旨在从多媒体辅助信息中提取最优价值的特征。

Alashkar[2] 提出一个基于MLP的推荐模型用户化妆品的推荐，这一模型使用两个相同的MLP来分别对专家规则和标记性的样本进行建模。通过极小化这两者之间的差异来对两个网络的参数进行更新。这一工作阐述了适用专家规则来指导MLP中的学习过程，尽管专家规则需要许多人工，但它的准确性很高。

Covington[17] 探索了使用MLP来进行YouTube的推荐。这一系统将推荐任务分为两步：候选集生成与候选集排序。候选集生成网络从所有的video库里获得一个几百的子集，候选集排序网络基于候选集生成一个top n的list。我们注意到关心更多的是特征工程（特征变换、特征归一化和特征交叉）和推荐模型的可伸缩性。


#### 4.2 基于自编码的推荐系统

有两类将自编码应用到推荐系统的方法：1. 在bottleneck 层使用自编码来学习到低维的特征表示， 2. 在reconstruction 层直接对评分矩阵的进行填充。


##### 4.2.1 仅仅基于自编码的推荐

AutoRec[90]使用用户向量`$r_u$` 或者item向量 `$r_i$`作为输入，来对它们进行重建。显然，它有两个变种，I-AutoRec和 U-AutoRec， 对应两种类型的输入。这里我们只介绍I-AutoRec，U-AutoRec 可以相应地推理得来。图4(a) 描述了I-AutoRec的结构，对指定`$r_i$`，重建方法是：
`$h(r_i, \theta) = f(W * g(V * r_i + \mu) + b)$`, 其中 `f` 和 `g`是激活函数，参数 `$\theta = \{W, V, \mu, b\}$`，目标函数定义如下：

`$argmin \sum\limits_{i=1}^N ||r_i - h(r_i, \theta)||^2 + \lambda * Regularization $`

其中，`$||\bigodot||^2$`代表只考虑观测到的评分，目标函数可以用resilient propagation 或者LBFGS，对于AutoRec有四点需要注意：

1. I-AutoRec比U-AutoRec更佳，这也许是用户向量的高方差导致的；
2. 不同激活函数的结合会显著影响模型的效果；
3. 适当增加隐含层的神经元个数能提升模型的效果，因为增大隐含层的维度可以使AutoRec更有能力来对输入的特性进行建模；
4. 增大网络的深度能进一步提高模型的效果。 


Collaborative Filtering Neural network (CFN)：CFN[98, 99]是AutoRec的推广，并拥有下面两个优点：1.用户去燥技术，使得CFN更加鲁棒，2.结合了其他信息比如说用户画像和商品属性来消除稀疏性和冷启动的影响。CFN的输入也是有用户和item两个方面的向量`$r_u$` 和 `$r_i$`。

作者介绍了三种广泛使用的corruption（腐蚀）方法来对输入加上噪音：高斯噪音、masking noise（遮蔽噪音）和椒盐噪音。为了更好处理缺失值，masking noise可以看成是对CFN施加了一个正则。

假设`$r_i$`是输入，损失函数定义如下：
`$$`




