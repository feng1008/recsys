## 深度学习常见优化算法及其在推荐系统上的应用


#### 一. 深度学习常见优化算法

> 深度学习的本质，实质上是对给定目标函数，寻找到一组泛化能力强的参数，使得在已知数据和未知数据上的某个损失函数达到最小。当目标函数与损失函数确定的时候，剩下的就是寻找一组最优的参数了，这时候优化算法就非常重要了（实际上不论cnn, rnn都可以看成是目标函数不同，损失函数和优化方法也是相通的）。其次，实际的应用中训练一个深度学习模型通常需要几天或者几周的时间，这时候优化算法的效率直接影响模型的训练效率。再次，在深度学习中，“ 滤波器的设计（特征提取）应该使用爬山算法（如梯度下降）而学得，而不应该由人工来设计”。因此特征提取也是依靠优化算法来学习的。
甚至有人认为：当深度学习不work, 那就是梯度下降不work。这里介绍的几种算法都是梯度下降的扩展。

##### sgd:

现实使用的sgd一般为mini-batch sgd（以下提到的sgd默认都为mini-batch sgd），mini-batch sgd则结合随机梯度下降和批梯度下降的优点。 批梯度下降每次计算梯度的时候都计算了所有数据，因此造成计算量巨大。而随机梯度下降每次只选择一个样本的梯度代替整个样本集的梯度，因此有较大噪音，不容易快速走到极小值点。

当数据集比较大的时候，数据的读入形式也是基于batch-size的读入。所以即便你的数据集好几百G的图像或文本，一台8G显存的机器也能hold住训练一个深度神经网络。当然对深度学习训练速度影响最大的参数也是batch-size的大小。

sgd 每次迭代参数按下列公式更新：

`$g = \nabla_{\theta}f({\theta}_t)$`

`$w_t\gets w_t - \eta * g $`

其中 `$g$` 是梯度， `$\eta$` 是学习率，也就是每一步的步伐，`$w$` 是要更新的参数。


#####  Momentum

momentum 可以理解为在sgd的基础上对梯度加了一个 ema 指数平滑，来消除梯度下降过程中的抖动（当然你也可以从物理学动量的角度来理解）。在动量法中，参数在各个方向上的移动不仅取决于当前的梯度，还取决历史各个梯度在方向上是否一致。梯度方向一致,步伐会加大；梯度方向变化,步伐减小;梯度接近0也能跳出陷阱不至于陷入局部最小。

`$g = \nabla_{\theta}f({\theta}_t)$`

`$m_t = \mu * m_{t-1} + (1 - \mu) * g$`

`$w_t\gets w_t - \eta * m_t $`

其中 `$\mu $`是衰减系数

特点：梯度方向一致，步伐增大；梯度方向改变，步伐减小。


##### Adagrad

Adagrad 是对学习率做了衰减：

`$g=\nabla_{\theta}f({\theta}_t)$`

`$n_t = n_{t-1} + g^2$`

`$w_t\gets w_t -  \tfrac{\eta}{\sqrt{n_t + \epsilon}}* g $`

其中`$\epsilon$`是维护系数稳定的参数，默认取1e-8

特点：梯度越大，步伐越小；随着迭代次数的增加，步伐逐渐减小；在迭代后期步伐接近为0.

##### RMSProp
RMSProp是在Adagrad的基础上加了一个ema指数平滑

`$g=\nabla_{\theta}f({\theta}_t)$`

`$r_t = \rho * r_{t-1} + (1 - \rho) * g * g$`

`$w_t = w_t - \tfrac{\eta}{\sqrt{r_t + \epsilon}}* g$`

所有参数与之前定义一致

##### Adam
Adam其实就是Momentum与RMSProp的结合，然后再修正偏差

`$g=\nabla_{\theta}f({\theta}_t)$`

`$m_t = \mu * m_{t-1} + (1 - \mu) * g$`

`$r_t = \rho * r_{t-1} + (1 - \rho) * g * g$`

`$\hat{m_t} = \frac{m_t}{1 - \mu}$`

`$\hat{r_t} = \frac{r_t}{1 - \rho}$`

`$w_t = w_t - \frac{\eta * \hat{m_t}}{\sqrt{\hat{r_t} + \epsilon}}$`

Adam目前是深度学习领域最常使用的算法，已被证明相比其他几种算法有很大优势。

当然还有Ftrl, Adadelta, Adamax, Nadam 等，这里不过多介绍了，tensorflow 对这些都有实现 https://www.tensorflow.org/api_guides/python/train  ，当然你也可以自己写。


#### 二. FM原理与tensorflow实现

FM的原理，网上有太多的资料可以参考，这里也不详细解释了。归根结底，FM改变了目标函数，将原来的二阶组合形式

`$y(x)= w_0+\sum\limits_{i=1}^nw_ix_i+\sum\limits_{i=1}^n\sum\limits_{j=i+1}^nw_{ij}x_ix_j$`

改变成了：

`$y(x)= w_0+\sum\limits_{i=1}^nw_ix_i + \frac{1}{2}\sum\limits_{f = 1}^k {({{(\sum\limits_{i = 1}^n {{v_{i,f}}{x_i}} )}^2} - \sum\limits_{i = 1}^n {v_{i,f}^2x_i^2} )} $`


其余损失函数和优化方法都没有做什么改变。FM原作者开源的 libfm 实现了sgd, sgda, als, mcmc四种优化方法。当然也有libfm的一个加强版libffm。

> 那么问题来了，在现在FM开源库到处可见（包括原作者开源的libfm, 还有libffm, fastFM, lightfm等）的情况下，为什么要用tensorflow？
> 
> 首先，从开发成本上看。举个例子，libfm实现了四种优化算法，但是如果我想尝试一种新的方法比如说adam（当然也不是很新），那我需要读懂原来的 C++ 代码 然后进行二次开发，那我要实现它在GPU上跑呢？那还需要自己写CUDA, 这成本就很大了。实际的一些研究工作中也是这样，当你一直用着C++  搞研究工作而cvpr提出一种新的方法，开源的代码用的是matlab，那你估计就不大可能尝试它了。另外在运行速度上，tensorflow有GPU版本，运行速度绝对比cpu跑的c++ 要快，当然C++    代码也可以运行在GPU上，但你如果手动写CUDA那就很蛋疼了。tensorflow 相当于把很多底层的运算都已经做好了而且支持GPU运算，做学术研究的的时候只需要把这些底层组件自己拼接起来，而且可以随意设计，切换目标函数、损失函数和优化算法。就比如前不久hinton放出来胶囊网络(capsnet) 没两天，github上就有人用tensorflow把它实现了。另外，据说tensorflow 在工业应用上的优势更强大，包括其在大数据上的运算能力和跨平台能力，这点我还没体会到。
> 
> 总之： tensor大法好。


接下来是用tensorflow实现一个fm的例子，当然github上也有一个开源的库 [tffm](https://github.com/geffy/tffm)。不多解释了，详细步骤看代码吧。


```
# 计算目标函数y
def predict(self, x):
        # 模型一阶项
	y_hat = tf.add(self.w0, tf.reduce_sum(tf.multiply(x, self.w), 1, keep_dims = True))

        # 如果有二阶项，则加上后面这一坨， 加上了二阶项才是一个fm， 否则就是一个普通的回归
	if self.has_intersection:
		interactions = tf.multiply(0.5, tf.reduce_sum(tf.subtract(
			tf.pow(tf.matmul(x, tf.transpose(self.v)), 2), tf.matmul(tf.pow(x, 2), tf.transpose(tf.pow(self.v, 2)))
		)))
		y_hat = tf.add(y_hat, interactions)
	return y_hat
```
上面的predict函数是将输入`$x$` 代入到模型中得到的预测结果。

```
# 计算loss， 可以是平方损失函数或者是对数损失函数
def loss_function(self, y, y_hat):
	loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_hat), 2))

        # 如果有正则化项，则损失函数需要加上正则化项
	if self.has_normal:
		l2_norm = tf.reduce_sum(tf.add(tf.multiply(tf.constant(self.lambda_w), tf.pow(self.w, 2)), tf.multiply(tf.constant(self.lambda_v), tf.pow(self.v, 2))))	
		loss = tf.add(loss, l2_norm)
	return loss
```
loss_function 函数的功能是计算预测值与真实值之间的误差，误差形式可以自己定义，当然也可以对`$w$` 和 `$v$`加上正则。
```
def get_optimizer(self):
        # 获取optimizer， 可以是adam, adagrad, sgd等，这些tensorflow都有实现，直接调用就可以了
	if self.method.lower() == 'adagrad':
		return tf.train.AdagradOptimizer(learning_rate=self.learning_rate, initial_accumulator_value=1e-8)
	elif self.method.lower() == 'adam':
		return tf.train.AdamOptimizer(learning_rate=self.learning_rate)
	elif self.method.lower() == 'momentum':
		return tf.train.MomentumOptimizer(learning_rate=self.learning_rate, momentum=0.95)
	else:
		return tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)
```
get_optimizer()的功能是获取一个optimizer， 可以是adam, adagrad, sgd等，这些tensorflow都有实现。

```
def build_model(self, x, y):
        # 计算loss
	loss = self.loss_function(y, self.predict(x))

        # 调用一个优化器（可以是sgd， adam， adagrad等）极小化loss
	optimizer = self.get_optimizer().minimize(loss)
	return optimizer
```
上面的build_model主要就是调用之前的几个函数， 先代入 `$x$` 到目标函数得到预测的 `$y$`，再计算其与真实目标值之间的loss， 最后调用一个optimizer极小化loss就可以了。

下面是训练过程：
```
def train(self):
        # 读入数据 
	all_data_x, all_data_y = self.load_data(os.path.join(DATA_PATH, self.all_data_file))
	train_x, test_x, train_y, test_y = train_test_split(all_data_x, all_data_y, test_size = 0.3)
	n, p = all_data_x.shape

        # 定义x, y两个 placeholder
	x = tf.placeholder('float', shape=[None, p])
	y = tf.placeholder('float', shape=[None, 1])

        # 定义fm的参数 w0, w 和 v
	self.w0 = tf.Variable(tf.zeros([1]), name = 'w0')
	self.w = tf.Variable(tf.zeros([p]), name = 'w')
	self.v = tf.Variable(tf.random_normal([self.hidden_factor, p], stddev=0.01), name = 'v')

        # build_model, 返回一个optimizer
	optimizer = self.build_model(x, y)
	# import pdb;pdb.set_trace()
	init = tf.global_variables_initializer()    # 初始化所有参数
	saver=tf.train.Saver([self.w0, self.w, self.v])     # 定义一个Saver用于保存模型
	
	with tf.Session() as sess:
		sess.run(init)
		for epoch in range(self.N_EPOCHS):
			if epoch % 500 == 0 and epoch > 0:
		    	        # 每500次迭代保存一遍模型
				saver.save(sess, self.save_file + '_' + str(epoch))
			# import pdb;pdb.set_trace()
			
			# 随机获取一个 batch_size 大小的样本集
			indices = np.arange(train_x.shape[0])
			np.random.shuffle(indices)
			t_x, t_y = train_x[indices[:self.batch_size]], train_y[indices[:self.batch_size]]
			
			# 将 batch feed给 optimizer
			sess.run(optimizer, feed_dict={x: t_x.toarray(), y: t_y})

		# print('MSE: ', sess.run(error, feed_dict={x: train_x.toarray(), y: train_y}))
		# loss = tf.reduce_sum(tf.pow(tf.subtract(y, self.predict(x)), 2))
		loss = self.valid_loss(x, y)
		print('Loss (regularized error):', sess.run(loss, feed_dict={x: train_x.toarray(), y: train_y}))
		
		# print('Predictions:', sess.run(self.predict(x), feed_dict={x: test _x.toarray(), y: test_y}))
		# print('Learnt weights:', sess.run(self.w, feed_dict={x: train_x.toarray(), y: train_y}))
		# print('Learnt factors:', sess.run(self.v, feed_dict={x: train_x.toarray(), y: train_y}))
```

训练的过程主要是读入数据，声明定义变量(tensor) ， 定义模型形式， 然后在一个Session里启动，当然还有一些保存模型等步骤，看代码的注释就可以了。因为读入的数据不是特别大，所以读入数据没有batch读入或使用稀疏存储等，特征处理有做稀疏存储。

用户测试的时候：

```
def user_recommendation(self, model_file, userid, item_list, top_k):
	result = []
	# import pdb;pdb.set_trace()
	user_item_array = np.vstack((np.tile(userid, len(item_list)), itemid_list)).T
	user_item_transform = self.transform_user_item(user_item_array)

	x = tf.placeholder('float', shape=[None, user_item_transform.shape[1]])

	graph = tf.get_default_graph()
	with tf.Session() as sess:
		sess.run(tf.global_variables_initializer())

                # 从保存的模型中重新把参数加载回来， 包括w0, w, v
		new_sess = tf.train.import_meta_graph(self.save_file + '_1000.meta')
		new_sess.restore(sess, self.save_file + '_1000')
		self.w0 = graph.get_tensor_by_name("w0:0")
		self.w = graph.get_tensor_by_name("w:0")
		self.v = graph.get_tensor_by_name("v:0")

                # predict, 返回预测结果最大的top_k的索引
		pred_y = sess.run(self.predict(x), feed_dict={x: user_item_transform.toarray()})

		ind = np.argsort(pred_y, axis = 0)[-top_k:user_item_transform.shape[0]]
		return [x[0] + 1 for x in ind]
```

跑几个试试：

![image](E:\share\feng\fm\tf_based\result\recommendation_result.png)

只是证明流程跑通了，代码重构，算法与模型优化是接下来需要做的事。



>  当然，除了tensorflow，也有其他一些开源的机器学习库比如说scikit-learn, caffe, torch, pytorch, mxnet, theano, cntk等。
> 
> 其中, scikit-learn （曾经）是传统机器学习最流行的库，但对深度学习没有涉及，当然在现在使用也很广泛。
> 
> caffe是第一个深度学习库，在tensorflow 出来之前搞深度学习的默认都是使用caffe，但caffe只专注于计算机视觉，对数据，NLP没有太多支持。
> 
> torch 和 theano是两个历史相对悠久在深度学习时代迅速转型的库，其中theano已经停止维护了，torch是facebook开源的，但一直没有流行的原因是它的接口语言是一门比较小众的语言lua。当然facebook在2017年3月开源了torch 的python 版本pytorch，当然如果是同时和tensorflow开源是可以与其一较高下的，现在开源python版已经过了那个时候了。
> 
> cntk是微软开源的，用的人好像不多。
> 
> mxnet是几个华人（同时也是xgboost的作者陈天奇李沐）搞的，在运行速度、使用方便性等很多方面也是很优秀，而且被亚马逊aws选为默认支持的深度学习框架，而且在分布式上支持比较好。但在使用广泛性上，还是tensorflow最流行，而且其贡献者太多。


#### 3. FM 与其他方法对比

###### FM与决策树
决策树（或者说gdbt更合适）也可以用来做特征组合，Facebook的文章就使用了gbdt做特征组合再输入到LR中来做CTR预估。GBDT每棵树的叶子节点可以看成是几个条件组合后的衍生出来的特征。而且通过改变树的深度可以很方便地获取更高阶的组合特征。所以决策树也非常适合做特征组合。但与FM不同的是，决策树不适合处理高维稀疏特征。如果满足某种特征组合（比如说`$x_1=1$` 和 `$X_2=1$`）的样本不够多，决策树自然也就很难学习到这一规则，特征稀疏的时候就更加了。而且决策树不适合用于online learning，试想一下当你用历史数据训练了一个模型，第二天又一批新的数据进来了，你跑GBDT的时候又需要把所有数据读入进来再进行训练，而且与LR, FM和神经网络不同的是，gbdt不是这种基于一个batch读入再使用梯度下降训练的，一方面内存容易溢出，另一方面也不能对用户的一些行为快速做出反应。 
 

###### FM与神经网络

同样地，神经网络（或者叫做MLP更合适，一般cnn，rnn都分别适用于图像或者语言）也不适合处理高维稀疏特征，如果把这么高维稀疏的特征feed给一个神经网络那整个神经网络会爆炸的。但是，将特征进行embedding（比如说NLP中的Word2vec）之后可以作为神经网络的输入。实际上，FM也可以看成是对高维稀疏特征的embedding，将每个特征用一个低维的向量来表示同时尽量保留原矩阵的信息。学习到的低维向量可以用来做item相似性的度量，也可以作为另一模型（比如神经网络，LR）的输入。Google在2016就提出了一种wide and deep 模型用作 Google Play的app推荐。





以上看法如有不正之处，欢迎指出。

---
#### 附录一 ：ubuntu 16.04安装配置GPU版tensorflow


这里只介绍在ubuntu下安装配置CUDA和tensorflow，使用centos的同学请自行研究吧， NVIDIA 官网给出的例子就是用的centos安装的。没有Nvidia的显卡就不用忙活了。


1.Ubuntu换源

安装好ubuntu系统后先把软件源换掉吧，不然在线安装软件会比较慢。可以使用清华,中科大或者网易的软件源。我当初因为 ** 情节使用了 *山大学的软件源，结果安装软件处处报错，后来换成中科大的就没问题了。
```
sudo vim /etc/apt/sources.list
```
将内容替换为:


```
deb https://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse
deb-src https://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse

deb https://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse
deb-src https://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse

deb https://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse
deb-src https://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse

deb https://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse
deb-src https://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse

## Not recommended
# deb https://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse
# deb-src https://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse
```

然后

```
sudo apt-get update 
```


2. 安装nvidia driver , 不然图形界面好丑

先把原有的驱动卸载了吧：

```
sudo apt-get remove --purge nvidia*
```
关闭LightDM, 然后按ctrl+alt+F1进入tty文本模式 
```
sudo service lightdm stop
```
在线安装nvidia驱动，安装完后重新启动LightDM

```
sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt-get update
sudo apt-get install nvidia-375
sudo apt-get install mesa-common-dev
sudo apt-get install freeglut3-dev
sudo service lightdm start
```
执行

```
nvidia-smi
```
如果出现如图界面表示安装成功:

![image](E:\share\feng\fm\tf_based\result\nvidia.png)


3. 安装CUDA8


到 [NVIDIA官网](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal)选择对应版本的cuda，据说deb版的好多坑，还是使用runfile版，下载下来的文件大概有1.6G。 然后


```
sudo sh cuda_8.0.27_linux.run
```
然后按提示进行选择。注意这时候会提示是否安装一个低版本的驱动 (Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 367.48?)，选 No。这里坑最多，要是发现装完后进入图形界面黑屏或者循环登录，就是这里的问题了。

默认会把cuda8 安装在 /usr/local/cuda-8.0，同时在 /usr/local 下会有个cuda 文件夹, 是 cuda-8.0 的软链接。

默认cuda 的路径也会加入到PATH里，如果没有也可以手动加下：

```
sudo vim /etc/profile
```
添加以下两行:
```
export PATH="$PATH:/usr/local/cuda-8.0/bin"
export LD_LIBRARY_PATH="/usr/local/cuda-8.0/lib64"
```
然后再
```
source /etc/profile
```
创建链接文件
```
sudo gedit /etc/ld.so.conf.d/cuda.conf
```
添加以下内容
```
/usr/local/cuda/lib64
```
执行下面命令使链接立即生效
```
sudo ldconfig
```

跑个CUDA的例子看看安装成功了没

```
cd /usr/local/cuda-8/samples/1_Utilities/deviceQuery
sudo make
sudo ./deviceQuery
```
![image](E:\share\feng\fm\tf_based\result\cuda_run.png)

4. 安装cudnn 

到 [nvidia cudnn官网](https://developer.nvidia.com/cudnn) 下载cudnn, 然后解压copy到cuda对应目录:

```
sudo　tar zxvf cudnn-8.0-linux-x64-v6.0.tgz
cd cuda
sudo cp include/cudnn.h /usr/local/cuda/include 
sudo cp lib64/libcudnn* /usr/local/cuda/lib64 
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*

```
如果后来发现版本不兼容，可以下一个低版本的然后同样把这些库文件cp到指定目录，不过最好先把原来的备份下。

5. 安装GPU版tensorflow

可以到 [清华大学软件源](https://mirrors.tuna.tsinghua.edu.cn/help/tensorflow/) 指定tensorflow 的源在线安装，速度会比较快。
```
sudo pip install \
  -i https://pypi.tuna.tsinghua.edu.cn/simple/ \
  https://mirrors.tuna.tsinghua.edu.cn/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp36-cp36m-linux_x86_64.whl
```



用cifar跑个cnn试试

```
python cifar10_cnn.py
```
![image](E:\share\feng\fm\tf_based\result\cifar_cnn.png)

看日志已经是用GPU在跑了。




